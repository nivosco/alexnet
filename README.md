AlexNet implementation in TensorFlow (Python3), with pre-trained weights (from Caffe):

 - Required libraries: scipy, numpy and tensorflow
 - Each layer was saved to a seperate .mat file
 - Credit to: http://www.cs.toronto.edu/~guerzhoy/tf_alexnet/
 - Model: https://github.com/BVLC/caffe/tree/master/models/bvlc_alexnet

Layers:
#         .conv(11, 11, 96, 4, 4, padding='VALID', name='conv1')
#         .lrn(2, 2e-05, 0.75, name='norm1')
#         .max_pool(3, 3, 2, 2, padding='VALID', name='pool1')
#         .conv(5, 5, 256, 1, 1, group=2, name='conv2')
#         .lrn(2, 2e-05, 0.75, name='norm2')
#         .max_pool(3, 3, 2, 2, padding='VALID', name='pool2')
#         .conv(3, 3, 384, 1, 1, name='conv3')
#         .conv(3, 3, 384, 1, 1, group=2, name='conv4')
#         .conv(3, 3, 256, 1, 1, group=2, name='conv5')
#         .fc(4096, name='fc6')
#         .fc(4096, name='fc7')
#         .fc(1000, relu=False, name='fc8')
#         .softmax(name='prob'))
 
